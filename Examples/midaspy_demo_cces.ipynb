{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "609c91af",
   "metadata": {},
   "source": [
    "### __MIDASpy demonstration__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1239507",
   "metadata": {},
   "source": [
    "MIDASpy's core functionalities are demonstrated here by using it to impute missing responses to the 2018 Cooperative Congressional Election Study (CCES), an electoral survey conducted in the United States whose size and complexity poses computational difficulties for many existing multiple imputation algorithms."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8752d9c",
   "metadata": {},
   "source": [
    "The full CCES has 525 columns and 60,000 rows, the latter corresponding to individual survey respondents. After removing variables that either require extensive preprocessing or are unhelpful for imputation purposes — open-ended string variables, time indices, and ZIP code variables — the dataset contains 349 columns. The vast majority of these variables are categorical and must therefore be one-hot encoded for most multiple imputation software packages — that is, each 1 × 60,000 categorical variable with K unique classes must be expanded into a K × 60,000 matrix of 1s and 0s — increasing their number to 1,914."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48c09dfe",
   "metadata": {},
   "source": [
    "_**Loading and preprocessing the data**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb5b5f7",
   "metadata": {},
   "source": [
    "We begin by loading MIDASpy, its dependencies, and additional packages called in the workflow. We then read in the formatted CCES data and sort variables into continuous, binary, and categorical types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5e9ff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sys\n",
    "import MIDASpy as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7608d31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in = pd.read_csv(\"cces_jss_format.csv\")\n",
    "cont_vars = [\"citylength_1\",\"numchildren\",\"birthyr\"]\n",
    "vals = data_in.nunique()\n",
    "cat_vars = list(data_in.columns[(vals.values > 2) & ~(data_in.columns.isin(cont_vars))])\n",
    "bin_vars = list(data_in.columns[vals.values == 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d325b60a",
   "metadata": {},
   "source": [
    "Next, we apply the `.binary_conv()` function to the list of binary variables (which are not in dummy form), before appending them and the continuous variables to a `constructor_list` object, the basis for our final preprocessed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e23551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bin = data_in[bin_vars].apply(md.binary_conv)\n",
    "constructor_list = [data_in[cont_vars], data_bin]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6e0da5",
   "metadata": {},
   "source": [
    "To one-hot encode categorical variables, we apply the `.cat_conv()` function to a dataframe containing them. We concatenate the resulting matrix to the existing `constructor_list` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bd9e10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat = data_in[cat_vars]\n",
    "data_oh, cat_col_list = md.cat_conv(data_cat)\n",
    "constructor_list.append(data_oh)\n",
    "data_0 = pd.concat(constructor_list, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f598191",
   "metadata": {},
   "source": [
    "The final preprocessing step, which is nonessential, is to scale all variables between 0 and 1 to aid model convergence. We use scikit-learn’s `MinMaxScaler()` function for this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afcc8148",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data_0)\n",
    "data_scaled = pd.DataFrame(data_scaled, columns = data_0.columns)\n",
    "na_loc = data_scaled.isnull()\n",
    "data_scaled[na_loc] = np.nan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c75e2495",
   "metadata": {},
   "source": [
    "_**Imputation**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f88f8b",
   "metadata": {},
   "source": [
    "Once the data are preprocessed, training a MIDAS network with MIDASpy is straightforward. We declare an instance of the `Midas` class, pass our data to this object (including the sorted variable names) with the `.build_model()` function, and train the network for 10 epochs with the `.train_model()` function. For the purposes of this illustration, we maintain most of MIDASpy’s default hyperparameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "381c6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = md.Midas(layer_structure= [256,256], vae_layer = False, seed= 89, input_drop = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6d34c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size index: [3, 178, 6, 8, 6, 3, 3, 6, 6, 4, 3, 59, 3, 3, 6, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 3, 5, 6, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 3, 6, 6, 6, 6, 6, 6, 6, 10, 10, 7, 4, 7, 8, 5, 8, 3, 5, 9, 5, 52, 17, 3, 3, 3, 3, 3, 6, 3, 23, 4, 7, 8, 12, 14, 11, 6, 6, 4, 7, 10, 5, 4, 4, 7, 3, 4, 6, 3, 7, 5, 4, 4, 4, 6, 5, 17, 51, 53, 53, 3, 98, 6, 6, 5, 17, 17, 4, 6, 3, 3, 3, 6, 6, 6, 10, 5, 5, 5, 5, 6, 5, 7, 5, 5, 5, 5, 224, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 51, 53, 53, 5, 51, 14, 5, 6, 5]\n",
      "\n",
      "Computation graph constructed\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MIDASpy.midas_base.Midas at 0x16a85c6d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.build_model(data_scaled, binary_columns = bin_vars, softmax_columns = cat_col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ab7e7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialised\n",
      "\n",
      "Epoch: 0 , loss: 186.26737846679688\n",
      "Epoch: 1 , loss: 169.38942487792968\n",
      "Epoch: 2 , loss: 163.48311638997396\n",
      "Epoch: 3 , loss: 159.68743997802736\n",
      "Epoch: 4 , loss: 157.04094825032553\n",
      "Epoch: 5 , loss: 154.82602157389323\n",
      "Epoch: 6 , loss: 153.35590602010092\n",
      "Epoch: 7 , loss: 152.05749235839843\n",
      "Epoch: 8 , loss: 151.08395079345703\n",
      "Epoch: 9 , loss: 150.22736969604492\n",
      "Training complete. Saving file...\n",
      "Model saved in file: tmp/MIDAS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MIDASpy.midas_base.Midas at 0x16a85c6d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.train_model(training_epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0ffaca",
   "metadata": {},
   "source": [
    "Once the model is trained, we draw a list of 10 completed datasets. When datasets are very large, as in this case, we recommend accessing each one separately rather than simultaneously holding all of them in memory. We thus construct a dataset generator using the `.yield_samples()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb0bd2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputations = imputer.yield_samples(m=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94f4131a",
   "metadata": {},
   "source": [
    "_**Analysis of completed datasets**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f2c772",
   "metadata": {},
   "source": [
    "We analyze the 10 completed datasets using MIDASpy’s inbuilt `combine()` function. We estimate a simple linear probability model in which `\"CC18_415a\"`, a respondent’s degree of support for giving the United States Environmental Protection Agency power to regulate carbon dioxide emissions,is regressed on `\"age\" (2018 − \"birthyr\")`, a respondent’s age.\n",
    "\n",
    "Users can ensure exact reproducibility of analytical results by saving completed datasets to disk. The trained MIDAS model itself is also saved by default to the location specified in the `savepath` argument of `Midas()`.\n",
    "\n",
    "As we scaled the input dataset prior to imputation with the `MinMaxScaler()` function, for each completed dataset we first invert this transformation via scikit-learn’s `.inverse_transform()` function and also convert predicted probabilities for `CC18_415a` into binary categories using a threshold of 0.5. To save memory, we append the relevant subset of the data, for analysis, to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43f664b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c23fdeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tmp/MIDAS\n",
      "Model restored.\n"
     ]
    }
   ],
   "source": [
    "for df in imputations:\n",
    "    df_unscaled = scaler.inverse_transform(df)\n",
    "    df_unscaled = pd.DataFrame(df_unscaled, columns = data_scaled.columns) \n",
    "    df['age'] = 2018 - df_unscaled['birthyr']\n",
    "    df['CC18_415a'] = np.where(df_unscaled['CC18_415a'] >= 0.5,1,0)\n",
    "    analysis_dfs.append(df.loc[:,[\"age\",\"CC18_415a\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "393ba27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = md.combine(y_var = \"CC18_415a\", X_vars = [\"age\"], df_list = analysis_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "605ef806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>estimate</th>\n",
       "      <th>std.error</th>\n",
       "      <th>statistic</th>\n",
       "      <th>df</th>\n",
       "      <th>p.value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>const</td>\n",
       "      <td>0.934493</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>169.459700</td>\n",
       "      <td>3056.421238</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>-0.005259</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>-49.160665</td>\n",
       "      <td>4565.125518</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    term  estimate  std.error   statistic           df  p.value\n",
       "0  const  0.934493   0.005515  169.459700  3056.421238      0.0\n",
       "1    age -0.005259   0.000107  -49.160665  4565.125518      0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
